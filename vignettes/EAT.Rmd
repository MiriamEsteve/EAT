---
title: "EAT: Efficiency Analysis Trees"
date: "`r Sys.Date()`"
author: "Miguel HernÃ¡ndez University"
output: 
  rmarkdown::html_vignette:
    # self_contained: no
vignette: >
  %\VignetteIndexEntry{EAT: Efficiency Analysis Trees}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<style>
  body {
    text-align: justify;
    }
</style>


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  warning = FALSE,
  message = FALSE
)
```

This vignette is intended to known the main functions of the `EAT` package. [Efficiency Analysis Trees](https://www.sciencedirect.com/science/article/pii/S0957417420306072) is an algorithm that estimates a production frontier in a data-driven environment by adapting regression trees. In this way, techniques from the field of **machine learning** are incorporated into solving problems in the field of **production theory**. From the latter, a series of concepts necessary for solving problems with the `EAT` library are introduced: 

* A **production frontier** is a boundary defined by those input and output combinations that are feasible and efficient. 

* A **D**ecision **M**aking **U**nit (**DMU**) is a observation of the dataset whose efficiency is to be assessed. A DMU will be efficient when it is located at the production frontier and will have room for improvement when it is located in the area underlying the border. A non-efficient DMU can become efficient through any of the following options: 

  * Reduce the amount of input used while keeping the same amount of output obtained.

  * Increase the amount of output obtained while keeping the same amount of input used.

  * Reduce the amount of input used and increase the amount of output obtained at the same time.

The Efficiency Analysis Trees modeling is aimed at capturing the maximum trends of a set of outputs. For this purpose, DMUs under the same resource paradigm are grouped into nodes and subsequently the maximum expected output is predicted for each node. The Efficiency Analysis Trees estimator results in a monotonic increasing frontier with a stepped form where each of these steps corresponds to a node of the tree containing homogeneus DMUs with efficient and non-efficient output levels.

In this section, an **EAT** model, an **RFEAT** model,  **FDH** model and a **DEA** model refer to a modeling carried out using Efficiency Analysis Trees technique, Random Forest + Efficiency Analysis Trees technique, Free Disposal Hull mathematical program or Data Envelopment Analysis model respectively. The functions developed in the `EAT` library will always be oriented to one of the 4 previous models (EAT, RFEAT, FDH or DEA) and can be divided into 7 categories depending on its purpose:

```{r table, echo = FALSE}
library(dplyr)

functions <- data.frame("Purpose" = c(rep("modeling", 2), 
                                      rep("tuning", 2), 
                                      rep("plotting", 2),
                                      rep("efficiency scoring", 3), 
                                      rep("scores plotting", 2),
                                      rep("prediction", 3), 
                                      rep("ranking", 2)), 
                        "Function name" = c("EAT", "RFEAT", 
                                            "bestEAT", "bestRFEAT", 
                                            "frontier", "plotEAT", 
                                            "efficiencyEAT", "efficiencyCEAT", "efficiencyRFEAT",
                                            "efficiencyDensity", "efficiencyJitter",
                                            "predictEAT", "predictRFEAT", "predictFDH",
                                            "rankingEAT", "rankingRFEAT"), 
                        "Usage" = c("Apply Efficiency Analysis Trees technique to a data frame.",
                                    "Apply Random Forest + Efficiency Analysis technique to a data frame.",
                                    "Tune an EAT model.",
                                    "Tune a RFEAT model.",
                                    "Graph the estimated frontier through an EAT model in a low dimensional scenario
                                    (FDH estimated frontier is optional).",
                                    "Graph a tree structure through an EAT model.",
                                    "Calculate DMU efficiency scores through an EAT model (through an FDH model is optional).",
                                    "Calculate DMU efficiency scores through a convexified  EAT model (through an DEA model is optional).",
                                    "Calculate DMU efficiency scores through an RFEAT model (through an FDH model is optional).",
                                    "Graph a density plot for a vector of efficiency scores (EAT, FDH and RFEAT are available).",
                                    "Graph a jitter plot for a vector of efficiency scores calculated through an EAT model.",
                                    "Predict the output through an EAT model.",
                                    "Predict the output through a RFEAT model.",
                                    "Predict the output through a FDH model.",
                                    "Calculate the variable importance through an EAT model.",
                                    "Calculate the variable importance through a RFEAT model.")
                        )

kableExtra::kable(functions) %>%
  kableExtra::kable_styling("striped", full_width = F) %>%
  kableExtra::collapse_rows(columns = 1, valign = "middle") %>%
  kableExtra::row_spec(c(1:2, 5:6, 10:11, 15:16), background = "#DBFFD6") %>%
  kableExtra::row_spec(c(3:4, 7:9, 12:14), background = "#FFFFD1") 
```

The `PISAindex` database is included as a data object in the `EAT` library and will be used to exemplify the package functions. On the one hand, the inputs correspond to 13 variables that define the socioeconomic context of a country by means of a score in the range [1-100] obtained from [Social Progress Index](https://www.socialprogress.org/). On the other hand, the performance of each country in the PISA exams is measured by the average score of its schools in the disciplines of Science, Reading and Mathematics and they have been collected from [PISA 2018 Results](https://www.oecd.org/pisa/Combined_Executive_Summaries_PISA_2018.pdf).

The following variables are collected for 72 countries that take the PISA exam:

* **Country**, **Continent** and a 3-letter code that identifies the country following the ISO 3166 ALPHA-3 as rownames.

* *Outputs* :

  * **S_PISA** : mean score on the PISA exam in Science.
  * **R_PISA** : mean score on the PISA exam in Reading.
  * **M_PISA** : mean score on the PISA exam in Mathematics.
  
* *Inputs* :

  * Basic Human Needs field : 
  
    * **NBMC** : Nutrition and Basic Medical Care.
    * **WS** : Water and Sanitation.
    * **S** : Shelter.
    * **PS** : Personal Safety.
    
  * Foundations of Wellbeing field :
  
    * **ABK** : Access to Basic Knowledge.
    * **AIC** : Access to Information and Communications. 
    * **HW** : Health and Wellness.
    * **EQ** : Environmental Quality.
    
  * Opportunity field :
  
    * **PR** : Personal Rights.
    * **PFC** : Personal Freedom and Choice.
    * **I** : Inclusiveness.
    * **AAE** : Access to Advanced Education.
    
  * **GDP_PPP** : Gross Domestic Product based on Purchasing Power Parity.
    
Therefore, `EAT` package will be applied in order to create homogeneous groups of countries in terms of their social characteristics (Basic Human Needs, Foundations of Wellbeing, Oportunity and GDP PPP per capita) and subsequently to know for each of these groups what is the maximum PISA score expected in one specific discipline or in more than one.

```{r seed}
# We save the seed for reproducibility of the results
set.seed(120)
```

```{r library}
library(eat)
data("PISAindex")
```

## Modeling a scenario with an input and an output. Plotting the frontier

### EAT()

The `EAT` function is the centerpiece of the `eat` library. `EAT` performs a regression tree based on CART methodology under a new approach that guarantees obtaining a frontier as estimator that fulfills the property of free disposability. This new technique has been baptized as Efficiency Analysis Trees. The development of the functions contained in the `EAT` library has been thought so that even true R novices can easily use the library. The minimum arguments of the function are the data (`data`) containing the study variables, the indexes of the predictor variables or inputs (`x`) and the indexes of the predicted variables or outputs (`y`). Additionally, the `numStop` and `fold` arguments are included for those more experienced users in the fields of machine learning or tree-based models. Modifying these two allows obtaining different frontiers and therefore selecting the one that best suits the needs of the analysis. `numStop` refers to the minimum number of observations in a node to be divided and is directly related to the size of the tree. The higher the value of `numStop` the smaller the size of the tree. On the other hand, `fold` refers to the number of parts in which the data set is divided to apply the cross-validation technique, although, in this case, its variation is not so directly related to size of the tree. The function returns an `EAT` object.

```{r EAT, eval = F}
EAT(data, x, y, 
    fold = 5,
    numStop = 5, 
    na.rm = TRUE)
```

* Example 1: `M_PISA ~ PFC`

```{r single.output, collapse = FALSE}
single_model <- EAT(data = PISAindex, 
                    x = 15, # input 
                    y = 3) # output
```

`print()` returns the tree structure where:

* `y` : vector of predictions.
* `MSE` : mean square error at the node.
* `n(t)` : number of DMUs at the node.
* `input name < / >= s` represents the division of the space.
* `<*>` indicates a leaf node.

```{r print.single.output, collapse = FALSE}
print(single_model)
```

`summary()` returns the following information:

* `Formula` : outputs ~ inputs

* `Summary for leaf nodes` where:
  * `id` : leaf node index.
  * `n(t)` : number of DMUs at the leaf node.
  * `%` : proportion of DMUs at the leaf node.
  * `output names` as many columns as outputs with the corresponding predictions in the leaf node.
  * `MSE` : mean square error at the leaf node.
  
* `Tree` where:
  * `Inner nodes` : number of inner nodes.
  * `Leaf nodes` : number of leaf nodes.
  * `Total nodes` : total number of nodes (inner nodes + leaf nodes).
  * `Total MSE` : mean square error at the tree.
  * `numStop` : numStop hyperparameter value.
  * `fold` : fold hyperparameter value.
  
* `Primary & surrogate splits` where:
  * `Node A --> {B, C}` indicates that node A has split into left child node B and right child node C.
  * `variable --> {MSE: , s: }` represents the division of the space with its mean square error.
  * `Surrogate splits` indicates the best possible split for each variable that has not been used to divide the node as `variable --> {tL_R: , tR_R: , s: }` where `tL_R and tR_R` represent the error for each child node and `s` the threshold. In the case of a single input, the surrogate splits do not appear.

```{r summary.single.output, collapse = FALSE}
summary(single_model)
```

`size()` returns the number of leaf nodes:

```{r size.single.output, collapse = FALSE}
size(single_model)
```

Additionally, `EAT_object[["tree"]][[id_node]]` or `EAT_object$tree[[id_node]]` returns a `list` that allows to know in greater detail the characteristics of a given node. The elements that define a node are the following:

* `id` : node index.
* `F` : father node index. 
* `SL` : left child node index.
* `SR` : right child node index.
* `index` : set of indexes corresponding to the observations in a node.
* `varInfo` : MSE in the left node, MSE in the right node and threshold for each variable.
* `R` : mean square error in a node.
* `xi` : index of the variable that produces the split in a node.
* `s` : threshold of the variable `xi` by which the split takes place.
* `y` : value(s) of the predicted variable(s) in a node.
* `a` : first Pareto-dominance coordinate to ensure the property of free disposability in the frontier.
* `b` : second Pareto-dominance coordinate to ensure the property of free disposability in the frontier.

```{r node.charac, collapse = FALSE}
single_model[["tree"]][[5]]
```

### frontier()

The `frontier` function displays the frontier estimated by the `EAT` function. The FDH estimated frontier can be plotted too if `FDH = TRUE`. Training DMUs can be showed by a scatterplot if `train.data = TRUE` and its color, shape and size can be modified with `train.color`, `pch` and `size` respectively. Finally, rownames can be included with `rwn = TRUE`.

```{r frontier, eval = F}
frontier(object,
         FDH = FALSE,
         train.data = FALSE,
         train.color = "black",
         pch = 19,
         rwn = FALSE,
         size = 1.5)
```

To continue, the frontier of the previous model is displayed. It can be seen how the frontier obtained by the `EAT` function generalizes the results of the frontier obtained through FDH, thus avoiding overfitting. The boundary estimated through Efficiency Analysis Trees generates 3 steps corresponding to the 3 leaf nodes (nodes 3, 4 and 5) obtained with the `EAT` function. For each of these steps, a level of efficiency in terms of the output is given with respect to the amount of input used (in this case level of `PFC`). In addition, we can appreciate 5 DMUs in the frontier: MDA (Moldova), SRB (Serbia), RUS (Russia), HUN (Hungary) and SGP (Singapur). These DMUs are efficient and the rest of the DMUs below its specific step should increase the amount of output obtained or reduce the amount of input utilized until reaching the boundary to be efficient. 

```{r single.output.frontier, fig.width = 7.2, fig.height = 6}
frontier <- frontier(object = single_model,
                     FDH = TRUE, 
                     train.data = TRUE,
                     rwn = TRUE)

plot(frontier)
```

## Modeling a multioutput scenario. Feature selection.

* Example 2: `S_PISA + R_PISA + M_PISA ~ NBMC + WS + S + PS + ABK + AIC + HW + EO + PR + PFC + I + AAE + GDP_PPP`

```{r multioutput.scenario, collapse = FALSE, eval = FALSE}
multioutput_model <- EAT(data = PISAindex, 
                         x = 6:18, # input 
                         y = 3:5) # output
```

### rankingEAT()

The second example presents a multiple output scenario where 13 inputs are used to model the 3 available outputs. In these situations, a selection of the most contributing variables may be recommended in order to reduce overfitting, improve precision and reduce future training times. `rankingEAT` allows a selection of variables by calculating a score of importance through Efficiency Analysis Trees technique. The user can specify the number of decimal units (`r`), include a barplot with the scores of importance (`barplot`) and display a horizontal line in the graph to facilitate the cut-off point between important and not relevant variables (`threshold`).

```{r ranking, eval = F}
rankingEAT(object,
           r = 2,
           barplot = TRUE,
           threshold = 70)
```

The importance score represents how influential the variable is in the model. In this case, the cut-off point is set at 70 and therefore important variables are considered: **AAE** (Acess to Advance Education), **WS** (Water and Sanitation), **NBMC** (Nutrition and Basic Medical Care), **HW** (Health and Wellness) and **S** (Shelter). 

```{r multioutput.importance, fig.width = 7.2, fig.height = 6, eval = FALSE}
rankingEAT(object = multioutput_model,
           r = 2,
           barplot = TRUE,
           threshold = 70)
```

## Graphical representation by a tree structure

### plotEAT()

Now, `frontier` cannot be used since we are in a multivariate scenario. `frontier` allows us to see the regions of the input space originated with `EAT` in a very clear way, however, this is impossible with more than two variables. In this case, it is provided the typical tree-structure in which the relations between the predicted variable(s) and the predictive variable(s) are showed.

In each node, we can obtain the following information:

* `id`: node index.
* `MSE`: mean square error in a node.
* `n(t)`: number of DMUs in a node.
* `input name` by which the split take place.
* `y` : vector of predictions.

```{r plotEAT, eval = FALSE}
plotEAT(object)
```

* Example 3: `S_PISA + R_PISA + M_PISA ~ NBMC + WS + S + HW + AAE`

```{r model.graph1, collapse = FALSE, eval = FALSE}
best_multioutput <- EAT(data = PISAindex, 
                        x = c(6, 7, 8, 12, 17), # input
                        y = 3:5, # output
                        numStop = 8,
                        fold = 6)
```

```{r graph1, fig.dim = c(8.4, 7.5), eval = FALSE}
plotEAT(object = best_multioutput)
```

* Example 4: `S_PISA ~ NBMC + S + I + GDP_PPP`

```{r model.graph2, collapse = FALSE, eval = FALSE}
best_multioutput2 <- EAT(data = PISAindex, 
                        x = c(6, 8, 12, 16, 18), # input
                        y = 3) # output
```

```{r graph2, fig.dim = c(8.4, 7.5), eval = FALSE}
plotEAT(object = best_multioutput2)
```

## EAT tuning

In this section, `PISAindex` is divided into a training subset with 70% of the DMUs and a test set with the other 30% of the DMUs. Next, the `bestEAT` function will be applied to find the value of the hyperparameters `numStop` and `fold` that minimize the mean square error calculated on the test sample from a Efficiency Analysis Tree trained with the training sample.

```{r training_test}
n <- nrow(PISAindex) # Observations in the dataset
t_index <- sample(1:n, n * 0.7) # Training indexes
training <- PISAindex[t_index, ] # Training set
test <- PISAindex[-t_index, ] # Test set
```

The `bestEAT` function requires a training set (`training`) on which to model an Efficiency Analysis Tree and a test set (`test`) on which to calculate the mean square error. The number of trees built is given by the number of different combinations that can be given by the `numStop` and `fold` arguments. `bestEAT` returns a data frame with the following columns:

* `numStop` : numStop hyperparameter value.
* `fold` : fold hyperparameter value.
* `MSE`: mean square error calculated on the test sample with the tree built with the training sample, numStop and fold values.
* `leaf`: number of leaf nodes of the tree.

```{r bestEAT, eval = F}
bestEAT(training, test,
        x, y,
        numStop,
        fold,
        na.rm)
```

Tuning for: 

`S_PISA + R_PISA + M_PISA ~ NBMC + WS + S + PS + ABK + AIC + HW + EO + PR + PFC + I + AAE + GDP_PPP`

`numStop = {3, 5, 7, 10}` and `fold = {5, 7}`

```{r eat.tuning1, collapse = FALSE, eval = FALSE}
bestEAT(training = training, 
        test = test,
        x = 6:18,
        y = 3:5,
        numStop = c(3, 5, 7, 10),
        fold = c(5, 7))
```

Tuning for: 

`S_PISA + R_PISA + M_PISA ~ NBMC + WS + S + HW + AAE`.

`numStop = {3, 5, 7, 10}` and `fold = {5, 7}`

```{r eat.tuning2, collapse = FALSE, eval = FALSE}
bestEAT(training = training, 
        test = test,
        x = c(6, 7, 8, 12, 17),
        y = 3:5,
        numStop = c(3, 5, 7, 10),
        fold = c(5, 7))
```

The best trees are given by the hyperparameters `{numStop = 5, fold = 5}` and `{numStop = 5, fold = 7}` in both cases and the difference in error between the all-variable model and the reduced model is only 4.6 units.

```{r bestmodel, collapse = FALSE, eval = FALSE}
bestmodel <- EAT(data = PISAindex,
                 x = c(6, 7, 8, 12, 17),
                 y = 3:5,
                 numStop = 5,
                 fold = 5)
```

```{r summary.bestmodel, collapse = FALSE, eval = FALSE}
summary(bestmodel)
```

## Efficiency scores. Graphical representation.

### Non-convex model: efficiencyEAT()

The efficiency scores are numerical values that indicate the degree of efficiency of a set of DMUs. It must be entered a dataset (`data`) and the corresponding indexes of input(s) (`x`) and output(s) (`y`). It is recommended that the dataset whose efficiency is to be calculated coincide with those used to estimate the frontier. However, it is also possible to calculate the efficiency scores for a new data set. The efficiency scores will be calculated using the mathematical programming model included in the argument `score_model`. The following models are available:

* `BCC_out`: Banker Charnes and Cooper output-oriented radial model with efficiency level at 1.
* `BCC_in`: Banker Charnes and Cooper input-oriented radial model with efficiency level at 1.
* `DDF`: Directional Distance Function with efficiency level at 0.
* `RSL_out`: output-oriented Rusell Model with efficiency level at 1.
* `RSL_in`: input-oriented Rusell Model with efficiency level at 1.
* `WAM`: Weighted Additive Model with efficiency level at 0.

If `FDH = TRUE` scores are also calculated through a FDH model.

```{r efficiencyEAT, eval = FALSE}
efficiencyEAT(data, x, y, 
              object,
              score_model,
              r = 4,
              FDH = TRUE,
              na.rm = TRUE)
```

```{r scoresEAT, collapse = FALSE}
scores_EAT <- efficiencyEAT(data = PISAindex,
                            x = 15, 
                            y = 3,
                            object = single_model, 
                            scores_model = "BCC_out",
                            r = 4,
                            FDH = TRUE)
```

```{r scoresEAT2, collapse = FALSE}
scores_EAT2 <- efficiencyEAT(data = PISAindex,
                            x = 15, 
                            y = 3,
                            object = single_model, 
                            scores_model = "BCC_in",
                            r = 4)
```

### Convex model: efficiencyCEAT()

`efficiencyCEAT` returns the efficiency scores for the convexified frontier obtained through Efficiency Analysis Trees. In this case, If `DEA = TRUE` scores are also calculated through a DEA model.

```{r efficiencyCEAT, eval = FALSE}
efficiencyCEAT(data, x, y, 
               object,
               score_model,
               r = 4,
               DEA = TRUE,
               na.rm = TRUE)
```

```{r scoresCEAT, collapse = FALSE}
efficiencyCEAT(data = PISAindex,
               x = 15, 
               y = 3,
               object = single_model, 
               scores_model = "BCC_out",
               r = 4,
               DEA = TRUE)
```

### efficiencyJitter()

`efficiencyJitter` returns a jitter plot from `ggplot2`. This graphic shows how DMUs are grouped into leaf nodes in a model built using the `EAT` function. Each leaf node groups DMUs with the same level of resources. The dot and the black line represent, respectively, the mean value and the standard deviation of the scores of its node. Additionally, efficient DMU labels will always be displayed based on the model entered in the `score_model` argument. Finally, the user can specify an upper bound (`upb`) and a lower bound (`lwb`) in order to show, in addition, the labels which efficiency score is between them. 

```{r efficiency_jitter, eval = FALSE}
efficiencyJitter(object, scores_EAT,
                 scores_model,
                 lwb = NULL, upb = NULL)
```

```{r jitter_single, collapse = FALSE, fig.width = 7.2, fig.height = 5}
efficiencyJitter(object = single_model,
                 scores_EAT = scores_EAT$EAT_BCC_out,
                 scores_model = "BCC_out",
                 lwb = 1.2)
```

```{r jitter_single2, collapse = FALSE, fig.width = 7.2, fig.height = 5}
efficiencyJitter(object = single_model,
                 scores_EAT = scores_EAT2$EAT_BCC_in,
                 scores_model = "BCC_in",
                 upb = 0.65)
```

Graphically, it is observed that if the BCC models are used to obtain the efficiency scores:

* Under output orientation, those DMUs that are arranged in the horizontal plane will be efficient.

* Under input orientation those DMUs that are arranged in the vertical plane will be efficient.

* If any DMU is located in a corner of the border, it will be efficient under both orientations.

```{r frontier_comparar, fig.width = 7.2, fig.height = 6, fig.align = 'center'}
plot(frontier)
```

### efficiencyDensity()

`efficiencyDensity` returns a density plot from `ggplot2`. In this way, the similarity between the scores obtained by the different available methodologies can be verified. 

```{r efficiency_density, eval = F}
efficiencyDensity(scores_EAT,
                  scores_FDH = NULL,
                  scores_RFEAT = NULL)

```

```{r density_single, collapse = FALSE, fig.width = 7.2, fig.height = 6, fig.align = 'center'}
efficiencyDensity(scores_EAT = scores_EAT$EAT_BCC_out,
                  scores_FDH = scores_EAT$FDH_BCC_out,
                  scores_RFEAT = NULL)

```

## Random Forest

### RFEAT()

Random Forest + Efficiency Analysis Trees (`RFEAT`) has also been developed with the aim of providing a greater stability to the results obtained by the `EAT` function. `RFEAT` function requires the `data` containing the variables for the analysis, `x` and `y` corresponding to the inputs and outputs indexes respectively, the minimun number of observation in a node for a split to be attempted (`numStop`) and `na.rm` to ignore observations with `NA` cells. All these arguments are used for the construction of the `m` individual Efficiency Analysis Trees that make up the random forest. Finally, the argument `s_mtry` indicates the number of inputs that can be randomly selected in each split. It can be set as any integer although there are also certain predefined values. Being, $n_{x}$ the number of inputs, $n_{y}$ the number of outputs and $n(t)$ the number of observations in a node, the available options in `s_mtry` are: 

* `Breiman` = $\frac{n_{x}}{3}$
* `DEA1` = $\frac{n(t)}{2} - n_{y}$
* `DEA2` = $\frac{n(t)}{3} - n_{y}$
* `DEA3` = $n(t) - 2 \cdot n_{y}$
* `DEA4` = $min(\frac{n(t)}{n_{y}}, \frac{n(t)}{3} - n_{y})$

```{r RF, eval = FALSE}
RFEAT(data, x, y,
      numStop = 5, m = 50,
      s_mtry = "Breiman",
      na.rm = TRUE)
```

```{r RFmodel, eval = FALSE}
forest <- RFEAT(data = PISAindex, 
                x = 6:18, # input 
                y = 3:5, # output
                numStop = 5, 
                m = 5,
                s_mtry = "Breiman",
                na.rm = TRUE)
```

## Predictions

As any other Machine Learning algorithm, `EAT` performs predictions by `predictEAT` function. `predictEAT` returns a `data.frame` with the data and the expected output(s) for a set of observations. The arguments to the `predictEAT` function are `object` (an `EAT` object) and `newdata` (dataframe with input variables). 

```{r predict, eval = F}
predictEAT(object, newdata)
```

```{r prediction, collapse = F, eval = FALSE}
predictions_EAT <- predictEAT(object = smr_model,
                             newdata = test[, input])
```

Predictions for the `RFEAT` model are made using the `predictRFEAT` function. To do this, the output is predicted by each of the `m` individual trees trained and subsequently the mean value of all the predictions is obtained. `predictRFEAT` requires a `RFEAT` object (from `RFEAT` function) and a set of input variables to predict on (`newdata`) returning then, a dataframe with the inputs and predicted variables.

```{r predict_EAT, eval = FALSE}
predictRFEAT(object, newdata)
```

```{r predict_EAT_ex, eval = FALSE}
predictions_RFEAT <- predictRFEAT(forest, test[, input])
```

```{r EAT_vs_RFEAT, eval = FALSE}
names(predictions_EAT)[14:16] <- c("S_EAT", "R_EAT", "M_EAT")
names(predictions_RFEAT)[14:16] <- c("S_RFEAT", "R_RFEAT", "M_RFEAT")

EAT_vs_RFEAT <- cbind(test[, 3:5], predictions_EAT[, 14:16], predictions_RFEAT[, 14:16])

print(EAT_vs_RFEAT)
```

Finally, a specific method to calculate efficiency scores applied to `RFEAT` can be utilized using the `efficiencyRFEAT` function. 

```{r eff_scores, eval = FALSE}
efficiencyRFEAT(data = training,
                x = input,
                y = output,
                object = forest)
```

```{r scores_RF, eval = FALSE}
scoresRF <- efficiencyRFEAT(data = training,
                            x = input,
                            y = output,
                            object = forest)
```

And finally, a ranking of variable importance by `rankingRFEAT` where `object` is a `RFEAT`, `r` is the number of decimal units and a `barplot` can be included with `barplot = TRUE`.

```{r ranking_RFEAT, eval = FALSE}
rankingRFEAT(object, r = 2,
              barplot = TRUE)
```

```{r ranking_RFEAT_ex, fig.width = 10.5, fig.height = 8, fig.align = 'center', eval = FALSE}
rankingRFEAT(object = forest, r = 2,
             barplot = TRUE)
```

## Posible errors in EAT

### Categorical variables

```{r continent, eval = F}
# Continent is a character vector, so we transform it into a factor class
PISAindex$Continent <- as.factor(PISAindex$Continent)
```

The variables allowed in the algorithm are the following:

* Independent variables (inputs): numerical (`integer`, `double`, `numeric`) or ordinal categorical (`ordered` `factor`)
* Dependent variables (outputs): numeric (`integer`, `double`, `numeric`)

Now, we introduce Continent as factor variable. We should get an error message since the variable Continet is a nominal categorical variable and only ordered factors are allowed.

```{r preprocess_factor, error = TRUE, collapse = FALSE, eval = F}
# Input indexes
input <- c(3, 7:19)

# Output indexes
output <- 6

reading_model <- EAT(data = PISAindex, x = input, y = output)
```

However, ordinal categorical variables can be used in `EAT`. To do this, we are going to categorize the variable `GDP_PPP` into 4 different groups: `Low`, `Medium`, `High` and `Very high`

```{r GDP_PPP_category, eval = FALSE, eval = F}
PISAindex$GDP_PPP_cat <- cut(PISAindex$GDP_PPP,
                            breaks = c(0, 16.686, 31.419, 47.745, Inf),
                            include.lowest = T,
                            labels = c("Low", "Medium", "High", "Very high"))

class(PISAindex$GDP_PPP_cat)

# It is very important indicate order = T, before EAT function

PISAindex$GDP_PPP_cat <- factor(PISAindex$GDP_PPP_cat, order = T)

class(PISAindex$GDP_PPP_cat)
```

```{r categorized_model, eval = FALSE}
# Input indexes
input <- c(7:18, 20)

# Output indexes
output <- 6

categorized_model <- EAT(data = PISAindex, x = input, y = output,
                         numStop = 15)
```

### Presence of NAs values

Another possible source of errors can come from the presence of `NA` values. The argument, `na.rm` is set to `TRUE` by default, thus `NA` rows are ignored. However, it is interesting to know the possible error in case of presence of this type of values. For this purpose, we set the argument `na.rm = F` and model the Reading PISA score in 2018 when Spain did not obtain results. 
```{r narm, error = TRUE, collapse = FALSE, eval = F}
# Input indexes
x <- 7:19

# Output indexes
y <- 5

reading_model <- EAT(data = PISAindex, x = x, y = y, 
                     na.rm = F)
```

