---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# eat

The `EAT` algorithm performs a regression tree based on CART methodology under a new approach that guarantees obtaining a frontier as estimator that fulfills the property of free disposability. This new technique has been baptized as Efficiency Analysis Trees. Some of its main functions are:

* To create homogeneous groups of DMUs in terms of their inputs and to know for each of these groups, what is the maximum expected output.

* To know which DMUs exercise best practices and which of them do not obtain a performance according to their resources level.

* To know what variables are more relevant in obtaining efficient levels of output.

## Installation

You can install the released version of eat from [CRAN](https://CRAN.R-project.org) with:

``` r
install.packages("eat")
```

And the development version from [GitHub](https://github.com/MiriamEsteve/EAT) with:

``` r
devtools::install_github("MiriamEsteve/EAT")
```
## Example

```{r library}
library(eat)
data("PISAindex")
```

* EAT model with 1 input (`NBMC`) and 1 output (`S_PISA`)

```{r model1}
single_model <- EAT(data = PISAindex, 
                    x = 15, # input 
                    y = 3) # output
```

* Print an `EAT` object

```{r print.model1, collapse = FALSE}
print(single_model)
```

* Summary of an `EAT` object

```{r summary.model1, collapse = FALSE}
summary(single_model)
```

* Number of leaf nodes of an `EAT` object

```{r size.model1, collapse = FALSE}
size(single_model)
```

* Frontier levels of output for an `EAT` object

```{r frt.model1, collapse = FALSE}
frontier.levels(single_model)
```

* Descriptive analysis for an `EAT` object

```{r perf.model1, collapse = FALSE}
descriptiveEAT <- descrEAT(single_model)

descriptiveEAT
```

* Plot the frontier

```{r frontier, collapse = FALSE}
frontier(object = single_model,
         FDH = TRUE, 
         observed.data = TRUE,
         rwn = TRUE)

```

* EAT model with 13 inputs and 3 outputs

```{r model2, collapse = FALSE}
multioutput <- EAT(data = PISAindex, 
                   x = 6:18,
                   y = 3:5)
```

* Ranking of importance of variables for EAT

```{r ranking, collapse = FALSE}
rankingEAT(object = multioutput,
           barplot = TRUE,
           threshold = 70,
           digits = 2)
```

* Plot an EAT model

```{r plot, collapse = FALSE}
plotEAT(object = multioutput)
```

* Tuning an EAT model

```{r training_test, collapse = FALSE}
n <- nrow(PISAindex) # Observations in the dataset
t_index <- sample(1:n, n * 0.7) # Training indexes
training <- PISAindex[t_index, ] # Training set
test <- PISAindex[-t_index, ] # Test set

bestEAT(training = training, 
        test = test,
        x = 6:18,
        y = 3:5,
        numStop = c(5, 7, 10),
        fold = c(5, 7))
```

* Efficiency scores EAT

```{r eff_EAT, collapse = FALSE}

single_model <- EAT(data = PISAindex, 
                    x = 15, # input 
                    y = 3) # output

scores_EAT <-  efficiencyEAT(data = PISAindex,
                            x = 15, 
                            y = 3,
                            object = single_model, 
                            scores_model = "BCC.OUT",
                            digits = 3,
                            FDH = TRUE)
```

* Efficiency scores CEAT

```{r scoresCEAT, collapse = FALSE}
scores_CEAT <- efficiencyCEAT(data = PISAindex,
                              x = 15, 
                              y = 3,
                              object = single_model, 
                              scores_model = "BCC.INP",
                              digits = 3,
                              DEA = TRUE)
```

* Efficiency jitter plot

```{r jitter, collapse = FALSE}
efficiencyJitter(object = single_model,
                 df_scores = scores_EAT$EAT_BCC_OUT,
                 scores_model = "BCC.OUT",
                 lwb = 1.2)
```

* Efficiency density plot

```{r density, collapse = FALSE}
efficiencyDensity(df_scores = scores_EAT[, 3:4],
                  model = c("EAT", "FDH"))
```

* RFEAT model

```{r RFEAT_model, collapse = FALSE}
forest <- RFEAT(data = PISAindex, 
                x = 6:18, # input 
                y = 5, # output
                numStop = 5, 
                m = 30,
                s_mtry = "BRM",
                na.rm = TRUE)
```

* Print a `RFEAT` object

```{r print.RFEAT, collapse = FALSE}
print(forest)
```

* Plot the Out-of-Bag error for a forest made up of k trees

```{r plot.RFEAT, collapse = FALSE}
plotRFEAT(forest)
```

* RFEAT ranking

```{r rankingRFEAT, collapse = FALSE}
rankingRFEAT(object = forest, barplot = TRUE,
             digits = 2)
```

* Tuning a RFEAT model

```{r tuning.bestRFEAT, collapse = FALSE}
bestRFEAT(training = training, 
          test = test,
          x = 6:18,
          y = 3:5,
          numStop = c(5, 10),
          m = c(30, 40),
          s_mtry = c("BRM", "3"))
```

* RFEAT scores

```{r RFEAT_scores, collapse = FALSE}
efficiencyRFEAT(data = PISAindex,
                x = 6:18, # input
                y = 5, # output
                object = forest,
                FDH = TRUE)
```

* EAT and RFEAT predictions 

```{r models, collapse = FALSE}
input <- c(6, 7, 8, 12, 17)
output <- 3:5

EAT_model <- EAT(data = PISAindex, x = input, y = output)
RFEAT_model <- RFEAT(data = PISAindex, x = input, y = output)

# PREDICTIONS
predictions_EAT <- predict(object = EAT_model, newdata = PISAindex[, input])
predictions_RFEAT <- predict(object = RFEAT_model, newdata = PISAindex[, input])
```

Please, check the vignette for more details.