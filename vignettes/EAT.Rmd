---
title: "EAT: Efficiency Analysis Trees"
date: "`r Sys.Date()`"
author: "Miguel HernÃ¡ndez University"
output: 
  rmarkdown::html_vignette:
vignette: >
  %\VignetteIndexEntry{EAT: Efficiency Analysis Trees}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<style>
  body {
    text-align: justify;
    max-width: 75%;
    margin-left: auto;
    margin-right: auto;
    }
</style>


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  warning = FALSE,
  message = FALSE
)
```

This vignette is intended to know the main functions of `EAT` library. [Efficiency Analysis Trees](https://www.sciencedirect.com/science/article/pii/S0957417420306072) is an alghoritm by which a production frontier is obtained through and adaptation of regression trees based on CART. The generation of production frontiers falls within the field of efficiency analysis, of which some concepts must be known:

* A **production frontier** is a boundary defined for those feasible combinations of input and output that are efficient.
* A **DMU** (**D**ecision **M**aking **U**nits) is an observation of the dataset whose efficiency is to be assessed.
* A specific DMU is **efficient** when is located at the production frontier and it has room for improvement regarding its inputs or outputs when it is in the area below the frontier.

The `EAT` algorithm must be conceived as a modeling of the response variable (output) in order to know its most efficient levels for each of the different regions of the input space that are generated. Thus, subspaces with homogeneous DMUs (since they must share the characteristics of said subspace) are delimited and the maximun expected output for that subspace is provided. In this way, the `EAT` predictor results in a monotonic increasing frontier with a stepped form where each of these steps corresponds to a node of the tree which contains observations with efficient and non-efficient output levels.

Although the model training has only been described for a single response variable so far, multiple output scenarios are also available. Additionally, modeling of the response variable(s) can be done using individual CARTs for regression or using Random Forest. On the other hand, the `EAT` object can be plotted as a tree structure to illustrate the relationship between the predictors and the predicted variable and, in the case of a single input and a single output (`y ~ x`), a representation of the frontier is acceptable. Finally, a ranking of variables can be obtained, giving the possibility of making a feature selection.

With the purpose of clarifying the previously exposed contents, the `PISAindex` database is collected from [socialprogress](https://www.socialprogress.org/). This has been included in the `EAT` package and contains the followig features:

* 72 countries which take the PISA test.
* 3 variables related to information about the country (rownames included).
* 3 possible outputs corresponding to the PISA score in Science, Reading and Mathematics.
* 13 possible inputs: 
  * 4 related to Basic Human Needs field.
  * 4 related to Foundations of Wellbeing field.
  * 4 related to Opportunity field.
  * 1 corresponding to the Gross Domestic Product per capita adjuted by purchasing power parity.

More details in `help(PISAindex)`. 

Therefore, `EAT` will be applied in order to create homogeneous groups of countries in terms of their social characteristics (Basic Human Needs, Foundations of Wellbeing, Oportunity and GDP PPP per capita) and subsequently to know for each of these groups what is the maximum PISA score expected in one or more areas.

```{r seed}
# We save the seed for reproducibility of the results
set.seed(120)
```

```{r library}
library(eat)
data("PISAindex")
```

```{r training_test}
# We split into training and test datasets to assess the models

# Observations in the dataset
n <- nrow(PISAindex)

# Training indexes
t_index <- sample(1:n, n * 0.8)

# Training set
training <- PISAindex[t_index, ]

# Test set
test <- PISAindex[-t_index, ]
```

## Warming up: one input and one output scenario

The `EAT` function is the centerpiece of `eat` library. `EAT` performs a regression tree based on CART methodology under a new approach that guarantees obtaining a frontier that fulfills the property of free disposability. Its development has been thought so that even true R novices can easily use the library. The minimum arguments of the function are the data (`data`) containing the study variables, the indexes of the predictor variables or inputs (`x`) and the indixes of the predicted variables or outputs (`y`). Additionally, the `numStop` and `fold` arguments are included for those more experienced users in the field of Machine Learning and tree-based models. Modifying these two allows obtaining different frontiers and therefore selecting the one that best suits the needs of the analysis. `numStop` refers to the minimum number of observations in a node to be divided and is directly related to the size of the tree. The higher the value of `numStop` the smaller the size of the tree. On the other hand, `fold` refers to the number of parts in which the data set is divided to apply the cross-validation technique, although, in this case, its variation is not so directly related to size. The function returns an `EAT` object.

```{r EAT, eval = F}
EAT(data, x, y, 
    fold = 5,
    numStop = 5, 
    na.rm = TRUE)
```

The `frontier` function displays the frontier estimated by `EAT`. Training DMUs can be showed by a scatterplot if `train.data = TRUE` and its color, shape and size can be modified with `train.color`, `pch` and `size` respectively. Finally, rownames can be included with `rwn = TRUE`.

```{r frontier, eval = F}
frontier(object,
         train.data = FALSE,
         train.color = "black",
         pch = 19,
         rwn = FALSE,
         size = 1.5)
```

```{r single_scenario, collapse = FALSE}
# Input indexes
input <- 6

# Output indexes
output <- 3

# Modeling
single_model <- EAT(data = training, 
                    x = input, 
                    y = output)
```

The printed output of `EAT` clearly shows the number of groups formed with its error, size, proportion and the efficient levels of said groups regarding its outputs. Additionally, `EAT[["tree"]]` returns a `list` with the following elements for each node:

* **id**: node index.
* **F**: father node index.
* **SL**: left son index.
* **SR**: right son index.
* **index**: observation indexes in a node.
* **R**: mean square error in a node.
* **xi**: index of the variable that produces the split in a node.
* **s**: threshold of the variable xi by which the split takes place.
* **y**: values(s) of the pedicted variable(s) in a node.
* **a**: first Pareto-dominance coordinate to ensure free disposability.
* **b**: second Pareto-dominance coordinate to ensure free disposability.

To continue, the frontier of the previous model is displayed:

```{r single_scenario_frontier, fig.width = 10.5, fig.height = 6, fig.align = 'center'}
frontier <- frontier(object = single_model,
                     train.data = TRUE,
                     train.color = "#F8766D",
                     rwn = TRUE,
                     size = 1.5)

plot(frontier)
```

We can observe how the frontier has 4 steps corresponding to the 4 leaf nodes obtained in the `EAT` model. For each of these steps, a level of efficiency in terms of the output is given with respect to the amount of inputs (in this case level of `NBMC`) used by the observations contained in the step. In addition, we can appreciate 4 DMUs in the horizontal plane of the frontier: IDN (Indonesia), MYS (Malaysia), LTV (Latvia) and SGP (Singapur). These are efficient and the rest of observations below its specifical step should obtain the same level of output to them to be efficient.

Additionally, we could include more layers by `ggplot2`. In this case, we add the observations belonging to the test set.

```{r single_scenario_frontier_test, fig.width = 10.5, fig.height = 6, fig.align = 'center'}
frontier +
  ggplot2::geom_point(data = test, ggplot2::aes(x = NBMC, y = S_PISA))
```

## Singe output scenario & feature selection

Next, we are going to model the response variable `S_PISA` based on all the available inputs.

```{r science_model, collapse = FALSE}
input <- 6:18

output <- 3

science_model <- EAT(data = training, x = input, y = output)
```

Now, `frontier` cannot be used since we are in a multivariate scenario. `frontier` allows us to see the regions of the input space originated with `EAT` in a very clearly way, however, this is impossible with more than 1 input and 1 output. In this case, it is provided the typical tree structure in which the relations between the predicted variable(s) and the predictive variable(s) are showed. `EAT_plot` performs a tree plot in the same line of simplicity for the user, since only the `EAT` object have to be introduced. 

```{r EAT_plot, fig.width = 10.5, fig.height = 9, fig.align = 'center', eval = FALSE}
EAT_plot(object)
```

```{r science_plot, fig.width = 10.5, fig.height = 9, fig.align = 'center'}
EAT_plot(object = science_model)
```

In each node, we can obtain the following information:

* **id**: node index.
* **R**: mean square error in a node.
* **Samples**: number of observations in a node.
* **Variable**: name of the variable that produces the split.
* **y**: vector corresponding to the output prediction.

In this example, we have used 13 inputs for modeling. `EAT` allows a feature selection by `ranking_EAT` or `ranking_RFEAT` (more details later). `ranking_EAT` calculates variable importance for an EAT_object. The user can specify the number of decimal units (`r`), include a barplot with the scores of importance (`barplot`) and a broken line to display in the graph (`threshold`).

```{r ranking, eval = F}
ranking_EAT(object,
            r = 2,
            barplot = TRUE,
            threshold = 70)
```

```{r science_importance, fig.width = 10.5, fig.height = 6, fig.align = 'center'}
ranking_EAT(object = science_model,
            r = 2,
            barplot = TRUE,
            threshold = 70)
```

Now, we carry out a feature selection by the score obtained in `ranking_EAT`. We set `threshold` in 70 and we select those features whose importance is greater than this value, that is, **S**, **GDP_PPP**, **NBMC**, **HW** and **I**. We repeat the analysis:

```{r science_var_reduced_model, collapse = FALSE}
# Input indexes
input <- c(6, 8, 12, 16, 18)

# Output index
output <- 3

science_var_reduced_model <- EAT(data = training, x = input, y = output)
```


```{r compare_models, collapse = FALSE}
cat("Science model --> RMSE: ", science_model[["model"]][["RMSE"]], "| length: ", science_model[["model"]][["nodes"]])

cat("Science variables model reduced --> RMSE: ", science_var_reduced_model[["model"]][["RMSE"]], "| length: ", science_var_reduced_model[["model"]][["nodes"]])
```

In this way we can, on the one hand, know which are the most important variables for obtaining maximum levels of our output(s) and, on the other hand, repeat the analysis with fewer variables and then, reducing computation time.

```{r science_reduced_plot, fig.width = 10.5, fig.height = 9, fig.align = 'center'}
EAT_plot(object = science_var_reduced_model)
```

In this section, we also deal with `fold` and `numStop` arguments (by default both are 5). This last modeling, with `fold = 5` and `numStop = 5`, results in the tree shown above with 23 nodes. The tree size is highly dependent on the `numStop` argument, which indicates how much the minimum number of observations must be in a node to be considered a leaf node. So, higher values in `numStop` smaller size of the tree. About the `fold` argument, it is related to the cross-validation technique for pruning and indicates how many parts the data set has been divided into to select the training and test parts. Although it is not directly related to the size of the tree, its modification can lead to different frontiers. So now, we introduce `numStop = 8` expecting a smaller tree.

```{r science_reduced_model_second, collapse = FALSE}
# Input indexes
input <- c(6, 8, 12, 16, 18)

# Output index
output <- 3

science_var_reduced_numStop <- EAT(data = training, 
                                   x = input, 
                                   y = output,
                                   numStop = 8)
```

```{r compare_models2, collapse = FALSE}
cat("Science model --> RMSE: ", science_model[["model"]][["RMSE"]], "| length: ", science_model[["model"]][["nodes"]])

cat("Science variables model reduced --> RMSE: ", science_var_reduced_model[["model"]][["RMSE"]], "| length: ", science_var_reduced_model[["model"]][["nodes"]])

cat("Science variable model reduced NumStop --> RMSE: ", science_var_reduced_numStop[["model"]][["RMSE"]], "| length: ", science_var_reduced_numStop[["model"]][["nodes"]])
```

This new model, with 8 fewer variables than the first model and specifying `numStop = 8`, achieves a great balance between the error and the size of the tree compared to the two previous models.

```{r science_reduced_model_second_plot, fig.width = 10.5, fig.height = 8, fig.align = 'center'}
EAT_plot(object = science_var_reduced_numStop)
```

## Example 2: the multioutput scenario

A very engaging point of the `EAT` algorithm is the possibility of modeling multi-output scenarios in a natural way. It should be noted that this does not result in more complex syntax or interpretations. In the following example, all the available inputs are used to obtain a vector of maximum output level corresponding to the grades of Science, Reading and Mathematics.

```{r smr_model, collapse = FALSE}
# Input indexes
input <- 6:18

# Output indexes
output <- 3:5

smr_model <- EAT(data = training, 
                 x = input, 
                 y = output,
                 numStop = 7)
```

```{r smr_model_plot, fig.width = 10.5, fig.height = 8, fig.align = 'center'}
EAT_plot(object = smr_model)
```

As any other Machine Learning algorithm, `EAT` performs predictions by `predict_EAT` function. `predict_EAT` returns a `data.frame` with the data and the expected output(s) for a set of observations. The arguments to the `predict_EAT` function are `object` (an `EAT` object) and `newdata` (dataframe with input variables). 

```{r predict, eval = F}
predict_EAT(object, newdata)
```

```{r prediction, collapse = F}
predictions_EAT <- predict_EAT(object = smr_model,
                           newdata = test[, input])
```

## Efficiency scores

Efficiency scores are numerical values which indicates the grade of efficiency of certain DMU. Depending on the distance utilized, the efficiency paradigm changes. `efficiency_scores` provides a numeric vector with the efficiency score for each DMU and a brief descriptive analysis. Note that for `efficiency_FDH` it is not necessary to introduce the `EAT` object as an argument (`object`).

```{r efficiency, eval = FALSE}
efficiency_EAT(data, x, y, 
               object,
               score_model,
               r = 4)

efficiency_FDH(data, x, y, 
               score_model,
               r = 4)
```

The following models are available:

* `EAT_BCC_out` or `FDH_BCC_out`: Banker Charnes and Cooper distance with output orientation.
* `EAT_BCC_in` or `FDH_BCC_in`: Banker Charnes and Cooper distance with input orientation.
* `EAT_DDF` or `FDH_DDF`: Directional Distance Function.
* `EAT_RSL_out` or `FDH_RSL_out`: Rusell Model distance with output orientation.
* `EAT_RSL_in` or `FDH_RSL_in`: Rusell Model distance with input orientation.
* `EAT_WAM` or `FDH_WAM`: Weighted Additive Model distance.

In addition, a number of decimal units (`r`) can be added for calculating scores. We calculate the scores for EAT and FDH by the single_model. 

```{r scores, collapse = FALSE}
scores_EAT <- efficiency_EAT(data = training,
                             x = 6, 
                             y = 3,
                             object = single_model, 
                             scores_model = "EAT_BCC_out",
                             r = 4)

scores_FDH <- efficiency_FDH(data = training,
                             x = 6, 
                             y = 3,
                             scores_model = "FDH_BCC_out",
                             r = 4)
```

Two graphic representations are available:

* A jitter plot from `ggplot2` is provided. DMUs are grouped in nodes (same input paradigm) and its score are showed. A black point represents the score mean in a group and the line the standard deviation. Finally, the user can specify an upper bound (`upb`) and a lower bound (`lwb`) in order to show only the labels which efficiency score is between them. 

```{r efficiency_jitter, eval = FALSE}
efficiency_jitter(object, scores_EAT,
                  lwb = 0, upb = 1)
```

```{r jitter_single, collapse = FALSE, fig.width = 10.5, fig.height = 8, fig.align = 'center'}
efficiency_jitter(object = single_model,
                  scores_EAT = scores_EAT$EAT_BCC_out,
                  upb= 1)
```

We verify that, indeed, those DMUs with an efficiency level equal to or less than 1 (shown with the label) are those that are arranged in the horizontal steps of the frontier.

```{r frontier_comparar, fig.width = 10.5, fig.height = 6, fig.align = 'center'}
plot(frontier)
```

* A density plot from `ggplot2` is available too. `scores_EAT` is necessary while `scores_FDH` is optional. The result is a plot with one or both scores distributions in red for EAT and in blue for FDH.

```{r efficiency_density, eval = F}
efficiency_density(scores_EAT,
                   scores_FDH = NULL)

```

```{r density_single, collapse = FALSE, fig.width = 10.5, fig.height = 8, fig.align = 'center'}
efficiency_density(scores_EAT = scores_EAT$EAT_BCC_out,
                   scores_FDH = scores_FDH$FDH_BCC_out)

```

## Random Forest

Random Forest EAT (`RFEAT`) has also been developed with the aim of providing a greater stability to the results obtained by `EAT`. The function requires the `data` containing the variables for the analysis, `x` and `y` corresponding to the inputs and outputs indexes respectively, the minimun number of observation in a node for a split to be attempted (`numStop`) and `na.rm` to ignore observations with `NA` cells. All these arguments are used for the construction of the `m` individual `EAT` trees that make up the random forest. Finally, the argument `s_mtry` indicates the number of inputs that can be selected in each split. Being, $n_{x}$ the number of inputs, $n_{y}$ the number of outputs and $N$ the sample size, the available options in `s_mtry` are: 

* `Breiman` = $\frac{n_{x}}{3}$
* `DEA1` = $\frac{N}{2} - n_{y}$
* `DEA2` = $\frac{N}{3} - n_{y}$
* `DEA3` = $N - 2 \cdot n_{y}$
* `DEA4` = $min(\frac{N}{n_{y}}, \frac{N}{3} - n_{y})$


```{r RF, eval = FALSE}
RFEAT(data, x, y,
      numStop = 5, m,
      s_mtry = "Breiman",
      na.rm = TRUE)
```

```{r RF_data}
input <- 6:18
output <- 3:5

forest <- RFEAT(data = training, 
                x = input, y = output,
                numStop = 7, m = 10,
                s_mtry = "Breiman",
                na.rm = TRUE)
```

Predictions for the `RFEAT` model are made using the `predict_RFEAT` function. To do this, the output is predicted by each of the `m` individual trees trained and subsequently the mean value of all the predictions is obtained. `predict_RFEAT` requires a `RFEAT` object (from `RFEAT` function) and a set of input variables to predict on (`newdata`) returning then, a dataframe with the inputs and predicted variables.

```{r predict_EAT, eval = FALSE}
predict_RFEAT(object, newdata)
```

```{r predict_EAT_ex}
predictions_RFEAT <- predict_RFEAT(forest, test[, input])
```

```{r EAT_vs_RFEAT}
names(predictions_EAT)[14:16] <- c("S_EAT", "R_EAT", "M_EAT")
names(predictions_RFEAT)[14:16] <- c("S_RFEAT", "R_RFEAT", "M_RFEAT")

EAT_vs_RFEAT <- cbind(test[, 3:5], predictions_EAT[, 14:16], predictions_RFEAT[, 14:16])

print(EAT_vs_RFEAT)
```

Finally, a specific method to calculate efficiency scores applied to `RFEAT` can be utilized using the `efficiency_RFEAT` function. 

```{r eff_scores, eval = FALSE}
efficiency_RFEAT(data = training,
                 x = input,
                 y = output,
                 object = forest)
```

```{r scores_RF}
scoresRF <- efficiency_RFEAT(data = training,
                             x = input,
                             y = output,
                             object = forest)
```

And finally, a ranking of variable importance by `ranking_RFEAT` where `object` is a `RFEAT`, `r` is the number of decimal units and a `barplot` can be included with `barplot = TRUE`.

```{r ranking_RFEAT, eval = FALSE}
ranking_RFEAT(object, r = 2,
              barplot = TRUE)
```

```{r ranking_RFEAT_ex, eval = FALSE}
ranking_RFEAT(forest, r = 2,
              barplot = TRUE)
```

## Posible errors in EAT

### Categorical variables

```{r continent, eval = F}
# Continent is a character vector, so we transform it into a factor class
PISAindex$Continent <- as.factor(PISAindex$Continent)
```

The variables allowed in the algorithm are the following:

* Independent variables (inputs): numerical (`integer`, `double`, `numeric`) or ordinal categorical (`ordered` `factor`)
* Dependent variables (outputs): numeric (`integer`, `double`, `numeric`)

Now, we introduce Continent as factor variable. We should get an error message since the variable Continet is a nominal categorical variable and only ordered factors are allowed.

```{r preprocess_factor, error = TRUE, collapse = FALSE, eval = F}
# Input indexes
input <- c(3, 7:19)

# Output indexes
output <- 6

reading_model <- EAT(data = PISAindex, x = input, y = output)
```

However, ordinal categorical variables can be used in `EAT`. To do this, we are going to categorize the variable `GDP_PPP` into 4 different groups: `Low`, `Medium`, `High` and `Very high`

```{r GDP_PPP_category, eval = FALSE, eval = F}
PISAindex$GDP_PPP_cat <- cut(PISAindex$GDP_PPP,
                            breaks = c(0, 16.686, 31.419, 47.745, Inf),
                            include.lowest = T,
                            labels = c("Low", "Medium", "High", "Very high"))

class(PISAindex$GDP_PPP_cat)

# It is very important indicate order = T, before EAT function

PISAindex$GDP_PPP_cat <- factor(PISAindex$GDP_PPP_cat, order = T)

class(PISAindex$GDP_PPP_cat)
```

```{r categorized_model, eval = FALSE}
# Input indexes
input <- c(7:18, 20)

# Output indexes
output <- 6

categorized_model <- EAT(data = PISAindex, x = input, y = output,
                         numStop = 15)
```

### Presence of NAs values

Another possible source of errors can come from the presence of `NA` values. The argument, `na.rm` is set to `TRUE` by default, thus `NA` rows are ignored. However, it is interesting to know the possible error in case of presence of this type of values. For this purpose, we set the argument `na.rm = F` and model the Reading PISA score in 2018 when Spain did not obtain results. 
```{r narm, error = TRUE, collapse = FALSE, eval = F}
# Input indexes
x <- 7:19

# Output indexes
y <- 5

reading_model <- EAT(data = PISAindex, x = x, y = y, 
                     na.rm = F)
```

