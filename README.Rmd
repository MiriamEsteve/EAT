---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# eat

The `EAT` algorithm performs a regression tree based on CART methodology under a new approach that guarantees obtaining a frontier as estimator that fulfills the property of free disposability. This new technique has been baptized as Efficiency Analysis Trees. Some of its main functions are:

* To create homogeneous groups of DMUs in terms of their inputs and to know for each of these groups, what is the maximum output expected.

* To know which DMUs exercise best practices and which of them do not obtain a performance according to their resources level.

* To know what variables are more relevant in obtaining efficient levels of output.

## Installation

You can install the released version of eat from [CRAN](https://CRAN.R-project.org) with:

``` r
install.packages("eat")
```

And the development version from [GitHub](https://github.com/MiriamEsteve/EAT) with:

``` r
# install.packages("devtools")
devtools::install_github("MiriamEsteve/EAT")
```
## Example

```{r library}
library(eat)
data("PISAindex")
```

* EAT model with 1 input (`NBMC`) and 1 output (`S_PISA`)

```{r model1}
single_model <- EAT(data = PISAindex, 
                    x = 15, # input 
                    y = 3) # output
```

* Print an EAT object

```{r print.model1, collapse = FALSE}
print(single_model)
```

* Summary of an EAT object

```{r summary.model1, collapse = FALSE}
summary(single_model)
```

* Number of leaf nodes of an EAT object

```{r size.model1, collapse = FALSE}
size(single_model)
```

* Frontier levels of output for an EAT object

```{r frt.model1, collapse = FALSE}
frontier.levels(single_model)
```

* Descriptive analysis for an EAT object

```{r perf.model1, collapse = FALSE}
descriptiveEAT <- descrEAT(single_model)

# Descriptive for the nodes 1-3
descriptiveEAT[1:3]
```

* Plot the frontier

```{r frontier, collapse = FALSE}
frontier(object = single_model,
         FDH = TRUE, 
         train.data = TRUE,
         rwn = TRUE)

```

* EAT model with 18 inputs and 3 outputs

```{r model2, collapse = FALSE}
multioutput <- EAT(data = PISAindex, 
                   x = 6:18,
                   y = 3:5)
```

* Ranking of importance of variables for EAT

```{r ranking, collapse = FALSE}
rankingEAT(object = multioutput,
           r = 2,
           barplot = TRUE,
           threshold = 70)
```

* Plot an EAT model

```{r plot, collapse = FALSE}
plotEAT(object = multioutput)
```

* Tuning an EAT model

```{r training_test, collapse = FALSE}
n <- nrow(PISAindex) # Observations in the dataset
t_index <- sample(1:n, n * 0.7) # Training indexes
training <- PISAindex[t_index, ] # Training set
test <- PISAindex[-t_index, ] # Test set

bestEAT(training = training, 
        test = test,
        x = 6:18,
        y = 3:5,
        numStop = c(5, 7, 10),
        fold = c(5, 7))
```

* Efficiency scores EAT

```{r eff_EAT, collapse = FALSE}
scores_EAT <-  efficiencyEAT(data = PISAindex,
                            x = 15, 
                            y = 3,
                            object = single_model, 
                            scores_model = "BCC_out",
                            r = 3,
                            FDH = TRUE)
```

* Efficiency scores convex EAT

```{r scoresCEAT, collapse = FALSE}
scores_CEAT <- efficiencyCEAT(data = PISAindex,
                              x = 15, 
                              y = 3,
                              object = single_model, 
                              scores_model = "BCC_in",
                              r = 3,
                              DEA = TRUE)
```

* Efficiency jitter plot

```{r jitter, collapse = FALSE}
efficiencyJitter(object = single_model,
                 scores_EAT = scores_EAT$EAT_BCC_out,
                 scores_model = "BCC_out",
                 lwb = 1.2)
```

* Efficiency density plot

```{r density, collapse = FALSE}
efficiencyDensity(scores = scores_EAT[, 3:4],
                  model = c("EAT", "FDH"))
```

* RFEAT model

```{r RFEAT_model, collapse = FALSE}
forest <- RFEAT(data = PISAindex, 
                x = 6:18, # input 
                y = 5, # output
                numStop = 5, 
                m = 30,
                s_mtry = "Breiman",
                na.rm = TRUE)
```

* Print a RFEAT object

```{r print.RFEAT, collapse = FALSE}
print(forest)
```

* Plot the Out-of-Bag error for a forest of k trees

```{r plot.RFEAT, collapse = FALSE}
plotRFEAT(forest)
```

* RFEAT ranking

```{r rankingRFEAT, collapse = FALSE}
rankingRFEAT(object = forest, r = 2,
             barplot = TRUE)
```

* Tuning a RFEAT model

```{r tuning.bestRFEAT, collapse = FALSE}
bestRFEAT(training = training, 
          test = test,
          x = 6:18,
          y = 3:5,
          numStop = c(5, 10),
          m = c(30, 35, 40),
          s_mtry = c("Breiman", "3"))
```

* RFEAT scores

```{r RFEAT_scores, collapse = FALSE}
efficiencyRFEAT(data = PISAindex,
                x = 6:18, # input
                y = 5, # output
                object = forest,
                FDH = TRUE)
```

* EAT, RFEAT and FDH predictions 

```{r models, collapse = FALSE}
input <- c(6, 7, 8, 12, 17)
output <- 3:5

which(is.na(PISAindex), arr.ind = TRUE)

# FDH does not accept NA rows, so we exclude ESP

EAT_model <- EAT(data = PISAindex[- 32, ],
                 x = input,
                 y = output)

RFEAT_model <- RFEAT(data = PISAindex[- 32, ],
                     x = input,
                     y = output)

# PREDICTIONS

predictions_EAT <- predictEAT(object = EAT_model,
                              newdata = PISAindex[- 32, input])

predictions_RFEAT <- predictRFEAT(object = RFEAT_model,
                                  newdata = PISAindex[- 32, input])

predictions_FDH <- predictFDH(data = PISAindex[- 32, ],
                              x = input,
                              y = output)
```

Please, check the vignette for more details.